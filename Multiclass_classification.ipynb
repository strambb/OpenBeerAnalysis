{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitc30deacdfc314bf0ab55258624adc68b",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing a Multilabel classification\n",
    "## Aim: predicting the cat_name given: abv, country, cat_name , descript (if available)\n",
    "\n",
    "Steps:  \n",
    "1. Generate dummies  \n",
    "2. Standardize abv  \n",
    "3. Pre-split the data   \n",
    "4. Test-train-split    \n",
    "5. Build Preprocessing pipeline  \n",
    "6. Build Model  \n",
    "7. Build Pipeline  \n",
    "8. Assess Model   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, FunctionTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, r2_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define multiclass train test splitter from \n",
    "def multilabel_sample(y, size=1000, min_count=5, seed=None):\n",
    "    \"\"\" Takes a matrix of binary labels `y` and returns\n",
    "        the indices for a sample of size `size` if\n",
    "        `size` > 1 or `size` * len(y) if size =< 1.\n",
    "        The sample is guaranteed to have > `min_count` of\n",
    "        each label.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if (np.unique(y).astype(int) != np.array([0, 1])).all():\n",
    "            raise ValueError()\n",
    "    except (TypeError, ValueError):\n",
    "        raise ValueError('multilabel_sample only works with binary indicator matrices')\n",
    "\n",
    "    if (y.sum(axis=0) < min_count).any():\n",
    "        raise ValueError('Some classes do not have enough examples. Change min_count if necessary.')\n",
    "\n",
    "    if size <= 1:\n",
    "        size = np.floor(y.shape[0] * size)\n",
    "\n",
    "    if y.shape[1] * min_count > size:\n",
    "        msg = \"Size less than number of columns * min_count, returning {} items instead of {}.\"\n",
    "        warn(msg.format(y.shape[1] * min_count, size))\n",
    "        size = y.shape[1] * min_count\n",
    "\n",
    "    rng = np.random.RandomState(seed if seed is not None else np.random.randint(1))\n",
    "\n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        choices = y.index\n",
    "        y = y.values\n",
    "    else:\n",
    "        choices = np.arange(y.shape[0])\n",
    "\n",
    "    sample_idxs = np.array([], dtype=choices.dtype)\n",
    "\n",
    "    # first, guarantee > min_count of each label\n",
    "    for j in range(y.shape[1]):\n",
    "        label_choices = choices[y[:, j] == 1]\n",
    "        label_idxs_sampled = rng.choice(label_choices, size=min_count, replace=False)\n",
    "        sample_idxs = np.concatenate([label_idxs_sampled, sample_idxs])\n",
    "\n",
    "    sample_idxs = np.unique(sample_idxs)\n",
    "\n",
    "    # now that we have at least min_count of each, we can just random sample\n",
    "    sample_count = int(size - sample_idxs.shape[0])\n",
    "\n",
    "    # get sample_count indices from remaining choices\n",
    "    remaining_choices = np.setdiff1d(choices, sample_idxs)\n",
    "    remaining_sampled = rng.choice(remaining_choices,\n",
    "                                   size=sample_count,\n",
    "                                   replace=False)\n",
    "\n",
    "    return np.concatenate([sample_idxs, remaining_sampled])\n",
    "\n",
    "\n",
    "def multilabel_sample_dataframe(df, labels, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a dataframe `df` and returns a sample of size `size` where all\n",
    "        classes in the binary matrix `labels` are represented at\n",
    "        least `min_count` times.\n",
    "    \"\"\"\n",
    "    idxs = multilabel_sample(labels, size=size, min_count=min_count, seed=seed)\n",
    "    return df.loc[idxs]\n",
    "\n",
    "def multilabel_train_test_split(X, Y, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a features matrix `X` and a label matrix `Y` and\n",
    "        returns (X_train, X_test, Y_train, Y_test) where all\n",
    "        classes in Y are represented at least `min_count` times.\n",
    "    \"\"\"\n",
    "    index = Y.index if isinstance(Y, pd.DataFrame) else np.arange(Y.shape[0])\n",
    "\n",
    "    test_set_idxs = multilabel_sample(Y, size=size, min_count=min_count, seed=seed)\n",
    "    train_set_idxs = np.setdiff1d(index, test_set_idxs)\n",
    "\n",
    "    test_set_mask = index.isin(test_set_idxs)\n",
    "    train_set_mask = ~test_set_mask\n",
    "\n",
    "    return (X[train_set_mask], X[test_set_mask], Y[train_set_mask], Y[test_set_mask])\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "name_beer       abv               name_brewery              city  \\\n0       Hocus Pocus  4.500000                  Magic Hat  South Burlington   \n1   BiÃ¨re Darbyste  5.107576      Brasserie de Blaugies          Blaugies   \n2     Isolation Ale  6.000000              Odell Brewing      Fort Collins   \n3   Nut Cracker Ale  5.900000  Boulevard Brewing Company       Kansas City   \n4  Never Summer Ale  5.940000       Boulder Beer Company           Boulder   \n\n         country  latitude  longitude  \\\n0  United States   44.4284   -73.2131   \n1        Belgium   50.3693     3.8270   \n2  United States   40.5894  -105.0630   \n3  United States   39.0821   -94.5965   \n4  United States   40.0267  -105.2480   \n\n                                            descript     cat_name  \\\n0  Our take on a classic summer ale.  A toast to ...  Other Style   \n1                                                NaN  Other Style   \n2  Ever been in a warm, cozy cabin and had a secr...  Other Style   \n3  Nutcracker Ale is Boulevardâ€™s holiday gift f...  Other Style   \n4                                                NaN  Other Style   \n\n                          style_name  \n0  Light American Wheat Ale or Lager  \n1  Light American Wheat Ale or Lager  \n2                      Winter Warmer  \n3                      Winter Warmer  \n4                      Winter Warmer  \n[[4.58458903e-03 1.47355325e-03 2.25804992e-04 ... 1.07500625e-05\n  0.00000000e+00 1.74894423e-02]\n [1.22392210e-03 8.02822909e-05 8.41336305e-05 ... 3.36950028e-05\n  0.00000000e+00 2.51862689e-03]\n [2.27809495e-03 3.73521125e-04 7.00427706e-05 ... 2.40388241e-05\n  0.00000000e+00 4.52406434e-03]\n ...\n [3.09500891e-04 4.72164550e-07 9.58695508e-05 ... 1.25298994e-04\n  0.00000000e+00 2.72583368e-04]\n [4.93953051e-04 1.26741980e-03 4.73300434e-05 ... 5.86841602e-04\n  0.00000000e+00 5.82470651e-04]\n [9.17908192e-04 3.10224947e-04 6.82716094e-05 ... 7.79241488e-03\n  0.00000000e+00 1.57856119e-03]]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.5390835579514824"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#Loading the data\n",
    "df = pd.read_csv(r\"data\\cleaned\\beer_cleaned.csv\")\n",
    "print(df.head())\n",
    "\n",
    "#define numeric columns\n",
    "LABELS = [\"style_name\"]\n",
    "NON_LABEL = [c for c in df.columns if c != \"style_name\"]\n",
    "NUMERIC = list(df.loc[:, df.dtypes != \"object\"].columns) # Non-label>numeric\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Writing in pipeline reuseable text-getter function\n",
    "def combine_text_columns(data_frame, to_drop=NUMERIC + LABELS):\n",
    "    \"\"\" Takes the dataset as read in, drops the non-feature, non-text columns and\n",
    "        then combines all of the text columns into a single vector that has all of\n",
    "        the text for a row.\n",
    "        \n",
    "        :param data_frame: The data as read in with read_csv (no preprocessing necessary)\n",
    "        :param to_drop (optional): Removes the numeric and label columns by default.\n",
    "    \"\"\"\n",
    "    # drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # replace nans with blanks\n",
    "    text_data.fillna(\"\", inplace=True)\n",
    "    \n",
    "    # joins all of the text items in a row (axis=1)\n",
    "    # with a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)\n",
    "\n",
    "#generating pipeline objects to use in pipeline\n",
    "get_numeric_features = FunctionTransformer(lambda x : x[NUMERIC], validate=False)\n",
    "get_text_features = FunctionTransformer(combine_text_columns, validate = False)\n",
    "\n",
    "\n",
    "#1. get dummies:\n",
    "dummy_labels = pd.get_dummies(df[\"style_name\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(df[NON_LABEL], dummy_labels, 0.2, 1)\n",
    "\n",
    "pipe = Pipeline([(\"union\",FeatureUnion([\n",
    "                                        (\"numerics\", Pipeline([\n",
    "                                                                (\"selector\",get_numeric_features),\n",
    "                                                                (\"imputer\", SimpleImputer()),\n",
    "                                                                (\"scaler\",StandardScaler())\n",
    "                                                                ])\n",
    "                                        ),\n",
    "                                        (\"texts\", Pipeline([\n",
    "                                                            (\"selector\", get_text_features),\n",
    "                                                            (\"vectorizer\", CountVectorizer(ngram_range=(1,2)))\n",
    "                                                            ])\n",
    "                                        )\n",
    "                                        ])\n",
    "                ),\n",
    "                (\"clf\", OneVsRestClassifier(LogisticRegression()))\n",
    "                ])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred_proba = pipe.predict_proba(X_test)\n",
    "print(y_pred_proba)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    ""
   ]
  }
 ]
}